{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Friction:\n",
    "\n",
    "    with open('system_new.txt', 'r') as txt:\n",
    "        system = '\\n'.join(txt.readlines())\n",
    "\n",
    "    def prompt(x):\n",
    "        p = f'The example dialogue is provided next.\\n\\n{x[\"context\"]}\\n\\n\\n'\n",
    "        try:\n",
    "            p += f'The response is provided below.\\n\\nResponse: {x[\"response\"]}\\n\\n\\n'\n",
    "        except KeyError:\n",
    "            p += f'The response is provided below.\\n\\nResponse: \\n\\n\\n'\n",
    "        p += 'What friction category if any?'\n",
    "        return p\n",
    "\n",
    "f = Friction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('pfb30/multi_woz_v22', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset[0]\n",
    "turns = d['turns']\n",
    "num_turns = len(turns['utterance'])\n",
    "for i in range(num_turns):\n",
    "    u = turns['utterance'][i]\n",
    "    a = turns['dialogue_acts'][i]\n",
    "    speaker_id = turns['speaker'][i]\n",
    "    if speaker_id == 1:\n",
    "        print(f\"\\nAssistant: {u}\\n\\t(Dialogue acts: {','.join(a['dialog_act']['act_type'])})\")\n",
    "    else:\n",
    "        print(f\"\\nUser: {u}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acts = []\n",
    "for d in dataset:\n",
    "    for a in d['turns']['dialogue_acts']:\n",
    "        all_acts.extend(a['dialog_act']['act_type'])\n",
    "print(len(all_acts))\n",
    "print(len(set(all_acts)))\n",
    "print(set(all_acts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_services = sum([d['services'] for d in dataset], [])\n",
    "print(set(all_services))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "all_selected_instances = []\n",
    "for act in tqdm(set(all_acts)):\n",
    "    if act.startswith('general'):\n",
    "        continue\n",
    "    selected_instances = []\n",
    "    for d in dataset:\n",
    "        turns = d['turns']\n",
    "        num_turns = len(turns['utterance'])\n",
    "        for i in range(num_turns):\n",
    "            u = turns['utterance'][i]\n",
    "            acts = turns['dialogue_acts'][i]['dialog_act']['act_type']\n",
    "            speaker_id = turns['speaker'][i]\n",
    "            if speaker_id == 1 and acts == [act]:\n",
    "                context = \"\"\n",
    "                for prev_i in range(i):\n",
    "                    if turns['speaker'][prev_i] == 0:\n",
    "                        context += f\"User: {turns['utterance'][prev_i]}\\n\"\n",
    "                    else:\n",
    "                        context += f\"Assistant: {turns['utterance'][prev_i]}\\n\"\n",
    "                new_d = {\n",
    "                    \"context\": context,\n",
    "                    \"response\": f\"Assistant: {u}\",\n",
    "                    \"dialogue_acts\": acts,\n",
    "                }\n",
    "                selected_instances.append(new_d)\n",
    "                if len(selected_instances) == 10:\n",
    "                    break\n",
    "        if len(selected_instances) == 10:\n",
    "                    break\n",
    "\n",
    "    #print(len(selected_instances))\n",
    "    all_selected_instances.extend(selected_instances)\n",
    "print(f\"Selected {len(all_selected_instances)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acttypes = ['book', 'inform', 'nobook', 'nooffer', 'offerbook', 'offerbooked', 'recommend', 'request', 'select']\n",
    "from tqdm import tqdm\n",
    "all_selected_instances = []\n",
    "for act in tqdm(acttypes):\n",
    "    if act.startswith('general'):\n",
    "        continue\n",
    "    selected_instances = []\n",
    "    for d in dataset:\n",
    "        turns = d['turns']\n",
    "        num_turns = len(turns['utterance'])\n",
    "        for i in range(num_turns):\n",
    "            u = turns['utterance'][i]\n",
    "            acts = turns['dialogue_acts'][i]['dialog_act']['act_type']\n",
    "            speaker_id = turns['speaker'][i]\n",
    "            #print(acts, act)\n",
    "            #break\n",
    "            if speaker_id == 1 and len(acts) == 1 and acts[0].lower().endswith(act):\n",
    "                context = \"\"\n",
    "                for prev_i in range(i):\n",
    "                    if turns['speaker'][prev_i] == 0:\n",
    "                        context += f\"User: {turns['utterance'][prev_i]}\\n\"\n",
    "                    else:\n",
    "                        context += f\"Assistant: {turns['utterance'][prev_i]}\\n\"\n",
    "                new_d = {\n",
    "                    \"context\": context,\n",
    "                    \"response\": f\"Assistant: {u}\",\n",
    "                    \"dialogue_acts\": acts,\n",
    "                }\n",
    "                selected_instances.append(new_d)\n",
    "                if len(selected_instances) == 50:\n",
    "                    break\n",
    "        if len(selected_instances) == 50:\n",
    "                    break\n",
    "\n",
    "    #print(len(selected_instances))\n",
    "    all_selected_instances.extend(selected_instances)\n",
    "print(f\"Selected {len(all_selected_instances)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selected_acts = sum([d['dialogue_acts'] for d in all_selected_instances], [])\n",
    "all_selected_act_types = [x.split('-')[-1].lower() for x in all_selected_acts]\n",
    "print(len(all_selected_acts))\n",
    "from collections import Counter\n",
    "print(Counter(all_selected_act_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from openai_utils import openai_caller\n",
    "\n",
    "idx = random.choice(range(len(all_selected_instances)))\n",
    "d = all_selected_instances[idx]\n",
    "print(f\"Context: {d['context']}\")\n",
    "print(f\"Response: {d['response']}\")\n",
    "print(f\"Dialog acts: {d['dialogue_acts']}\")\n",
    "\n",
    "prompt = Friction.system + Friction.prompt(d)\n",
    "messages = [{'role': 'system', 'content': prompt}]\n",
    "\n",
    "gpt_response = openai_caller(messages, max_new_tokens=256, model='gpt4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_caller.compute_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_caller.reset_tokens_used()\n",
    "annotated_data = []\n",
    "\n",
    "for d in tqdm(all_selected_instances):\n",
    "        prompt = Friction.system + Friction.prompt(d)\n",
    "        messages = [{'role': 'system', 'content': prompt}]\n",
    "        gpt_response = openai_caller(messages, max_new_tokens=256, model='gpt4o')\n",
    "        friction_anno = gpt_response.split('ANSWER = ')[-1]\n",
    "        new_d = d.copy()\n",
    "        new_d['friction_anno'] = friction_anno\n",
    "        new_d['gpt_response'] = gpt_response\n",
    "        annotated_data.append(new_d)\n",
    "print(f\"Annotation cost: ${openai_caller.compute_cost():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "annotations = [x['friction_anno'] for x in annotated_data]\n",
    "print(Counter(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    x = random.choice(annotated_data)\n",
    "    if \"NoBook\" in x['dialogue_acts'][0]:\n",
    "        break\n",
    "print(f\"Context: {x['context']}\")\n",
    "print(f\"Response: {x['response']}\")\n",
    "print(f\"Dialog acts: {x['dialogue_acts']}\")\n",
    "print(f\"Friction annotation: {x['friction_anno']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acttype_frictionanno_counter = Counter()\n",
    "for d in annotated_data:\n",
    "    for a in d['dialogue_acts']:\n",
    "        acttype = a.split('-')[-1].lower()\n",
    "        if len(d['friction_anno']) > 20:\n",
    "            continue\n",
    "        acttype_frictionanno_counter[(acttype, d['friction_anno'])] += 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "rows = set([x[0] for x in acttype_frictionanno_counter.keys()])\n",
    "cols = set([x[1] for x in acttype_frictionanno_counter.keys()])\n",
    "data = [[acttype_frictionanno_counter[(r, c)]/sum([acttype_frictionanno_counter[(r, c2)] for c2 in cols]) for c in cols] for r in rows]\n",
    "df = pd.DataFrame(data)#, index=rows, columns=cols)\n",
    "plt.figure(figsize=(8, 8), dpi=150)\n",
    "sns.heatmap(df, annot=True, fmt='.2f', cmap='viridis')\n",
    "plt.xlabel('Friction Category', fontsize=14)\n",
    "plt.ylabel('Dialog Act type', fontsize=14)\n",
    "plt.xticks(ticks=[x+0.5 for x in range(len(cols))], labels=cols, rotation=45, fontsize=12)\n",
    "plt.yticks(ticks=[x+0.5 for x in range(len(rows))], labels=rows, rotation=0, fontsize=12)\n",
    "plt.title('Fraction of instances in each MultiWoZ Dialog Act type \\nclassified under different Friction categories', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(annotated_data, open(f'data_new_prompt/multiwoz_friction_anno-{len(annotated_data)}instances.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows\n",
    "for r in rows:\n",
    "    print(r, sum([acttype_frictionanno_counter[(r, c)] for c in cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotations = json.load(open('data_new_prompt/multiwoz_friction_anno-450instances.json'))\n",
    "for x in annotations:\n",
    "    x['dialog_act_type'] = x['dialogue_acts'][0].split('-')[-1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "das = set([x['dialog_act_type'] for x in annotations])\n",
    "da2annos = {da: [x for x in annotations if x['dialog_act_type'] == da] for da in das}\n",
    "fcs = set([x['friction_anno'] for x in annotations])\n",
    "fc2annos = {fc: [x for x in annotations if x['friction_anno'] == fc] for fc in fcs}\n",
    "dafc2annos = {(da, fc): [x for x in annotations if x['dialog_act_type'] == da and x['friction_anno'] == fc] for da in das for fc in fcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I need to find a swimming pool in the north.\n",
      "Assistant: There are 2 swimming pools in the north, jesus green outdoor pool and kings hedges learner pool. Which one would you like more information on?\n",
      "User: Kings Hedges sounds good, what postcode are they in? And do they have an entrance fee?\n",
      "Assistant: Kings Hedges Learner Pool is in postcode cb42xh. Their entrance fee is a bit of a mystery, however, I don't have any firm numbers. Can I help with anything else?\n",
      "User: Yes, I need some information about a restaurant called pizza express.\n",
      "Assistant: Certainly! What information specifically are you looking for?\n",
      "User: I'd like to know if I can book a reservation for 7 people at 18:00 monday.\n",
      "\n",
      "RESPONSE TO ANNOTATE: Assistant: Were you looking for a booking at Pizza Express or Pizza Express Fen Ditton? They are both in the centre of town.\n",
      "\n",
      "ANNOTATION: Probing\n",
      "GPT REASONING: The response \"Assistant: Were you looking for a booking at Pizza Express or Pizza Express Fen Ditton? They are both in the centre of town.\" includes a question that seeks to clarify which specific location the user is interested in. This is an example of the \"Probing\" category, as the assistant asks a question to clarify something in the conversation.\n",
      "\n",
      "ANSWER = Probing\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#x = random.choice(da2annos[\"MiscOther\"])\n",
    "#x = random.choice(fc2annos[\"Probing\"])\n",
    "x = random.choice(dafc2annos[('select', 'Probing')])\n",
    "\n",
    "print(x['context'])\n",
    "\n",
    "print(\"RESPONSE TO ANNOTATE:\", x['response'])\n",
    "\n",
    "print(\"\\nANNOTATION:\", x['friction_anno'])\n",
    "print(\"GPT REASONING:\", x['gpt_response'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('hai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37056d97ceeb25f821c06bc9e03f17ba4a16f5dc42aed1fd1eeb8c2a2859b3a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
